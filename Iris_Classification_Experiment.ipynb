{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics  \n",
    "from sklearn.metrics import accuracy_score,precision_score, recall_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>146</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>147</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>148</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>149</td>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>150</td>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  \\\n",
       "0      1            5.1           3.5            1.4           0.2   \n",
       "1      2            4.9           3.0            1.4           0.2   \n",
       "2      3            4.7           3.2            1.3           0.2   \n",
       "3      4            4.6           3.1            1.5           0.2   \n",
       "4      5            5.0           3.6            1.4           0.2   \n",
       "..   ...            ...           ...            ...           ...   \n",
       "145  146            6.7           3.0            5.2           2.3   \n",
       "146  147            6.3           2.5            5.0           1.9   \n",
       "147  148            6.5           3.0            5.2           2.0   \n",
       "148  149            6.2           3.4            5.4           2.3   \n",
       "149  150            5.9           3.0            5.1           1.8   \n",
       "\n",
       "            Species  \n",
       "0       Iris-setosa  \n",
       "1       Iris-setosa  \n",
       "2       Iris-setosa  \n",
       "3       Iris-setosa  \n",
       "4       Iris-setosa  \n",
       "..              ...  \n",
       "145  Iris-virginica  \n",
       "146  Iris-virginica  \n",
       "147  Iris-virginica  \n",
       "148  Iris-virginica  \n",
       "149  Iris-virginica  \n",
       "\n",
       "[150 rows x 6 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"iris.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(columns=['Id','Species'],axis=1)\n",
    "Y=df['Species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=2)\n",
    "scaled = StandardScaler()\n",
    "scaled.fit(X_train)\n",
    "X_train = scaled.transform(X_train)\n",
    "X_test = scaled.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomforest(X_train,Y_train,X_test):\n",
    "    model = RandomForestClassifier(criterion='gini', max_depth=5, min_samples_leaf=5,\n",
    "                       n_estimators=100, n_jobs=-1, oob_score=True,\n",
    "                       random_state=42) \n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, Y_train)\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "    y_pred = model.predict(X_test)\n",
    "    return y_pred,model,training_time\n",
    "def eval_metric(model,y_pred,training_time):\n",
    "    oob=model.oob_score_\n",
    "    acc=accuracy_score(Y_test, y_pred)\n",
    "    precision = precision_score(Y_test, y_pred,average='macro')\n",
    "    recall = recall_score(Y_test, y_pred,average='macro')\n",
    "    return oob,acc,precision,recall,training_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DecisionTree(X_train,Y_train,X_test):\n",
    "    start_time = time.time()\n",
    "    model=DecisionTreeClassifier().fit(X_train,Y_train)\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "    test_pred_model=model.predict(X_test)\n",
    "    return test_pred_model,model,training_time\n",
    "def eval_metric(model,test_pred_model,training_time):\n",
    "    acc=accuracy_score(Y_test,test_pred_model)\n",
    "    precision = precision_score(Y_test, test_pred_model,average='macro')\n",
    "    recall = recall_score(Y_test, test_pred_model,average='macro')\n",
    "    return acc,precision,recall,training_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogRegression(X_train,Y_train,X_test):\n",
    "    start_time = time.time()\n",
    "    model=LogisticRegression()\n",
    "    model.fit(X_train,Y_train)\n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "    y_pred=model.predict(X_test)\n",
    "    return y_pred,model,training_time\n",
    "\n",
    "def eval_metric(model,y_pred,training_time):\n",
    "    acc=accuracy_score(Y_test,y_pred)\n",
    "    precision = precision_score(Y_test, y_pred,average='macro')\n",
    "    recall = recall_score(Y_test, y_pred,average='macro')\n",
    "    return acc,precision,recall,training_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM(X_train,Y_train,X_test):\n",
    "    start_time = time.time()\n",
    "    model=svm.SVC(kernel='linear')\n",
    "    model.fit(X_train, Y_train)\n",
    "    end_time = time.time()\n",
    "    y_pred = model.predict(X_test)\n",
    "    training_time = end_time - start_time\n",
    "    return y_pred,model,training_time\n",
    "\n",
    "def eval_metric(model,y_pred_class,training_time):\n",
    "    acc=accuracy_score(Y_test,y_pred_class)\n",
    "    precision = precision_score(Y_test, y_pred_class,average='macro')\n",
    "    recall = recall_score(Y_test, y_pred_class,average='macro')\n",
    "    return acc,precision,recall,training_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM_kernel(X_train,Y_train,X_test):\n",
    "    start_time = time.time()\n",
    "    model=svm.SVC(kernel='rbf')\n",
    "    model.fit(X_train, Y_train)\n",
    "    end_time = time.time()\n",
    "    y_pred = model.predict(X_test)\n",
    "    training_time = end_time - start_time\n",
    "    return y_pred,model,training_time\n",
    "\n",
    "def eval_metric(model,y_pred_class,training_time):\n",
    "    acc=accuracy_score(Y_test,y_pred_class)\n",
    "    precision = precision_score(Y_test, y_pred_class,average='macro')\n",
    "    recall = recall_score(Y_test, y_pred_class,average='macro')\n",
    "    return acc,precision,recall,training_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy= 0.9666666666666667\n",
      "Precision= 0.9629629629629629\n",
      "Recall= 0.9583333333333334\n",
      "Time(in sec)= 0.005040884017944336\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":  \n",
    "    y_pred,model,training_time=SVM_kernel(X_train,Y_train,X_test)\n",
    "    acc,precision,recall,training_time=eval_metric(model,y_pred,training_time)\n",
    "    print(\"Accuracy=\",acc)\n",
    "    print(\"Precision=\",precision)\n",
    "    print(\"Recall=\",recall)\n",
    "    print(\"Time(in sec)=\",training_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9666666666666667, np.float64(0.9629629629629629), np.float64(0.9583333333333334), 0.005040884017944336)\n"
     ]
    }
   ],
   "source": [
    "experiment_name = \"MLOps_CA_2\"\n",
    "run_name=\"SVM_kernel\"\n",
    "run_metrics = eval_metric(model, y_pred,training_time)\n",
    "print(run_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_experiment(experiment_name,run_name, run_metrics,model, \n",
    "                      run_params=None):\n",
    "    import mlflow\n",
    "    \n",
    "    #mlflow.set_tracking_uri(\"http://localhost:5000\") #uncomment this line if you want to use any database like sqlite as backend storage for model\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    \n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        \n",
    "        if not run_params == None:\n",
    "            for param in run_params:\n",
    "                mlflow.log_param(param, run_params[param])\n",
    "            \n",
    "        if isinstance(run_metrics, (list, tuple)):\n",
    "            for i, metric_value in enumerate(run_metrics):\n",
    "                #mlflow.log_metric('Accuracy',)\n",
    "                mlflow.log_metric(f'metric_{i}', float(metric_value))\n",
    "        \n",
    "        mlflow.sklearn.log_model(model, \"model\")\n",
    "        \n",
    "       \n",
    "        \n",
    "        mlflow.set_tag(\"tag1\", \"SVM_kernel\")\n",
    "        mlflow.set_tags({\"tag2\":\"Randomized Search CV\", \"tag3\":\"Production\"})\n",
    "            \n",
    "    print('Run - %s is logged to Experiment - %s' %(run_name, experiment_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/13 13:26:29 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run - SVM_kernel is logged to Experiment - MLOps_CA_2\n"
     ]
    }
   ],
   "source": [
    "create_experiment(experiment_name,run_name,run_metrics,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
